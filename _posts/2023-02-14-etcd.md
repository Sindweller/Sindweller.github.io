---
layout: default
title: 2023/02/14 ETCD 基础
author: sindweller <sindweller5530@gmail.com>
tags: [存储]
---

## 主要功能

- k-v存储
- 监听机制
- key的过期及续约机制，用于监控和服务发现（不停地续约以保证客户端是活着的）
- 原子Compare And Swap和Compare And Delete 用于分布式锁和leader选举
- 分布式存储，多节点冗余。
- 存储方式类似于目录结构（b+树）只有叶子结点才真正存储数据，相当于文件。叶子结点的父节点一定是目录，目录不能存储数据。

## 服务注册与发现

强一致性、高可用的服务存储目录（基于Raft算法）

一种注册服务和服务健康状况的机制。可以在etcd中注册服务，对注册的服务配置key TTL，定时保持服务的心跳以达到监控健康状态的目的。服务提供者不断通过lease来续约自己注册的服务，这样消费者可以从etcd获取这个服务的endpoint信息。

etcd会把失效的服务ip删除。

## 消息发布与订阅

分布式系统中最适用的组件间通信方式就是消息发布与订阅。

一旦订阅主题有消息发布，就会通知订阅者。

## CAS特性

构建一致性系统基本都需要CAS。修改内存值时带着条件修改。

Atomic Compare and Swap 在对key赋值时，客户端需要提供一些条件：

- prevExist key当前赋值前是否存在
- prevVlaue key当前赋值前的值 （原子操作）
- prevIndex key当前赋值前的Index

需要知道key当前情况才能赋值。

## Raft协议

基于quorum机制，大多数同意原则。

一致性模块把变更请求发送到所有Raft集群里的成员，并写入自己的日志模块，其他成员处理了变更请求后，写入状态机，并会把处理结果返回到一致性模块，只要多数成员确认变更，一致性模块就认可这个变更。客户端读取数据时是在状态机里获取数据，这个状态机里的数据是经过大多数同意的。

Term属性避免网络分片等导致集群分裂后，会有两个leader的情况。

Raft4.2.1引入Learner角色，新节点，commit相差很多，会一直同步数据，会导致leader心跳网络延迟，因此，learner节点增加时集群的quorum不变，不参与投票，以只读身份加入集群。数据同步后，learner可以变为follower。

每个节点有一个对leader的超时时间，达到之后如果没有收到来自leader的心跳包，就自动变为candidate，并向其他follower节点发送请求要求给自己投票。每个节点的超时时间都不同。在接收到leader心跳包时，会刷新超时时间。

当收到来自集群中超过半数的接受投票后，升级为leader节点，开始保存client过来的数据并向其他follower同步日志。如果没有达成一致，则随机一个等待时间再次发起投票。

leader节点定时向follower发送心跳包来保持自己地位。

每成功选举一次，leader的任期term都会+1。

如果是follower收到客户端请求，会转发给leader。

etcd增强部分：

- 安全性，如果follower掉队了，没有commit log。此时Safety机制就是用来保证新选举的leader的commitlog一定要是包含之前所有commit log，防止数据丢失
- 多个candidate冲突后会随机选择一个时间间隔再次发起投票。

## wal日志 write ahead log

- 二进制，解析出来后是数据结构logEntry
    - 字段type 0表示normal 1表示ConfChange：etcd本身的配置同步
    - 字段term 代表节点任期
    - 字段index 严格有序递增，代表变更序号
    - 字段data 二进制，将raft request对象的pb结构整个保存下来。
- 转换工具： tools/etcd-dump-log可以将二进制日志文件dump成文本来查看
- 一致性都通过同步wal日志实现，每个节点把从主节点收到的data apply到本地存储，Raft只关心日志的同步状态，如果本地存储实现有bug，比如没有正确将data apply到本地，会导致数据不一致。

## 存储机制

etcd v3 store：

- 内存中的索引 kvindex 基于golang实现的Btree
- 后端存储

etcd的后端可以对接多种存储，当前使用boltdb，是一个单机的支持事务的kv存储。etcd的事务就是基于boltdb的事务来实现的。实际存储时，boltdb中存储的key是reversion，value是etcd自己的key-value。从而实现多版本机制。

日志模块：先写wal日志，然后通过fsync落盘。

收到半数确认后，更新MatchIndex， apply状态机。

状态机是MVCC模块。

索引树里key=y, value没有保存真实的值，而是保存key所有关联的版本信息：modified version + generation（每一次创建删除都是一代）

落盘的树：key是revision，value是完整信息，包括create_revision modify_revision version value

## etcd如何保证一致性

在leader记录最新commit log的被多数确认的index到哪里了，避免没有同步到的follower变成leader。

## Watch机制

通过—prefix来进行range watch

开辟一块内存空间WatchableStore来满足watch需求，分为sync/unsync group

在etcd收到客户端请求时，如果请求携带了revision，会比较store当前revision。如果请求的revision大于当前revisioin则放入synced组中，否则放入unsynced组中。

etcd启动后台的goroutine持续同步unsynced的watcher，然后将其迁移到synced组。

v3的支持从任意版本开始watch，没有v2的1000条历史event表的限制。

## etcd成员重要参数

- name 默认default
- data-dir ‘${name}.etcd’ 如果不指定就默认在当前目录生成这个数据
- listen-peer-urls 集群成员间的通信走peer url
- listen-client-urls 客户端与服务端通信url

## 灾备

经常做备份

- 创建snapshot： etcdctl snapshot save snapshot.db
- 恢复数据: etcdctl snapshot restore snapshot.db —name infra2 —data-dir=/tmp/etcd/infra2 —initial-cluster infra0=http://…:33800,infra1=…

## 堆叠式高可用拓扑

APIServer

controller manager

scheduler

etcd

缺点是如果一个节点发生故障，etcd成员和控制平面实例都会丢失。

## 外部etcd集群的高可用拓扑

将控制平面和etcd成员解耦。但需要两倍于堆叠式拓扑的主机，至少需要三个主机用于控制面节点，三个主机用于etcd集群。

## 优化

事件分离：定义etcd server的overrides，/events转移到新的etcd上去。避免大量用于审计的事件消耗etcd资源，提升写入性能。

etcd尽量同地域部署。客户端到leader的并发连接过多时，可能导致follower节点法往leader的请求因为网络拥塞而被延迟处理；可以在节点上通过流量控制工具提高etcd成员之间发送数据的优先级来避免。

建议使用ssd

日志的形式保存数据（wallog），数据量会直线上升；etcd会以固定周期创建快照并移除旧日志文件。当修改次数累计到一定数量，通过—snapshot-count指定。

如果etcd 内存使用和磁盘使用过高，先考虑是否数据写入频率过高，调低快照触发的阈值。

设置合理的存储配额。如果一个节点的后台数据库的存储空间超出配额，就会进入维护模式，变为只读和只能删除。

自动压缩历史版本：丢弃给定版本之前的信息。

定期消除碎片化，压缩历史版本会导致存储空间出现碎片，需要定期释放调整。

## ETCD常见问题与解决方案

### 数据备份

etcd备份可以备份完整的集群信息，实现灾难恢复

- etcd提供了snapshot: `etcdctl snapshot save`
- 通过watch API server去watch k8s/etcd event 来备份event，将集群的所有变动都拉下来，需要做数据恢复的时候做一个回放
    
    *限制：这种回放对于subresource（例如pod）来说只能拿到pod的spec，但是status是不能恢复的。
    

备份频度的考量

- 时间长，能否接受user data lost？如果有外部资源配置，例如负载均衡，能否接受数据丢失导致的leak（泄漏）
- 时间短，对etcd有一定影响，做snapshot时，etcd会锁住当前数据（锁住磁盘）；并发写操作需要开辟新的空间进行增量写，会导致磁盘空间增长（时效性高会导致硬盘空间的磁盘碎片数量变多）。

如何保证备份时效性的同事防止磁盘爆掉？

自动执行defrag命令）——auto defrag，清理磁盘碎片

### 增强版backup方案

在etcd-operator创建的etcd pod中的backup会有一个sidecar，在里面置一个etcd watch client可以去监听snapshot（假设为每30min备份一次）之后的（revision之后的）所有事件。（例如，更新一个对象，etcd会有一个对应的put）

这种增量的信息可以每1min/10s存入一个remote volumn。做数据的restore时，先去拉去snapshot，再拉取增量，最后一起实现etcd的备份和恢复。

## 数据加密

非对称加密的形式保存，从etcd恢复数据也是加密数据。

EncryptionConfiguration这个kind里去设定，一般是secret。加密算法可以指定，没有key解不开。

## api查询etcd数据实例

例如：从12345版本开始监听所有对象的变化

这个查询是rest调用，然后会被转换成etcd的rest调用

```yaml
/api/v1/namespaces/test/pods?watch=1&resourceVersion=12345
```

apiserver也可以分页查询(默认查500个），返回的list里有一个continue_token，可以用它去查后边的

```yaml
/api/v1/pods?limit=100&continue=ENCODED_CONTINUE_TOKEN
```

List对象时如果不加resourceVersion，表明用户不信任APIServer的数据，请求会直接击穿APIServer的缓存，发送到etcd。所以一般要注意加上resourceVersion

Etcd没有过滤能力，APIServer侧通过Label过滤查询对象时，需要全量查询etcd数据。

## 坑

网络存储：虽然不需要备份，但是etcd的member总是跟不上

- 与apiserver之间链路阻塞，因为Daemonset不断去list pod，导致阻塞，节点状态上报不上来
- 故障分析中，造成少数etcd成员down，apiserver只探测端口是否活着，即使etcd响应503，也认为集群是健康的。apiserver会继续保持长连接，但是apiserver无法写数据到etcd，etcd也没有了转发到leader的能力，导致apiserver对应的节点状态上报失败，这些节点就会掉线。
    
    controller manager 会认为这40%节点坏了，就会把pod全部驱逐掉，就变成大面积故障。就是某些控制面的组件坏了，业务仍然能跑，但是强制驱逐后业务就受到了很大影响。
    
- 解决方案：给apiserver加一个healthcheck，查看etcd是否正常工作，如果异常，apiserver可以自杀，k8s节点能连到其他的apiserver节点上。